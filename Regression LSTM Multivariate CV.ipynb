{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "#from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to prepare data\n",
    "def prepare_data(x, dataset=\"train\"):\n",
    "    targets = ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']\n",
    "    x.date_time = pd.to_datetime(x['date_time'])\n",
    "    if(dataset==\"train\"):\n",
    "        x = pd.concat([x.loc[:, targets], \n",
    "                      x.iloc[:, :-3]], axis=1)\n",
    "    x = x.sort_values('date_time')\n",
    "    x = x.set_index('date_time')\n",
    "        \n",
    "    return x\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "# loss function\n",
    "def rmsle(y_true, y_pred):\n",
    "    #y_pred = K.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    loss = K.sqrt(msle(y_true, y_pred))\n",
    "    return loss\n",
    "\n",
    "# design model\n",
    "def get_model():\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "#    model.add(LSTM(100, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "#    model.add(LSTM(50))\n",
    "    model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(3, activation='softplus'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of lag hours\n",
    "n_hours = 3\n",
    "n_features = 8\n",
    "\n",
    "msle = tf.keras.losses.mean_squared_logarithmic_error\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    patience=15,\n",
    "    min_delta=0.0000001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "#New callback\n",
    "plateau = callbacks.ReduceLROnPlateau(\n",
    "    factor = 0.5,                                     \n",
    "    patience = 2,                                   \n",
    "    min_delt = 0.0000001,                                \n",
    "    cooldown = 0,                               \n",
    "    verbose = 0\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = prepare_data(train)\n",
    "test = prepare_data(test, dataset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "values_train = train.values.astype('float32')\n",
    "values_test = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2247, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler_train = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train = scaler_train.fit_transform(values_train[:, :9])\n",
    "\n",
    "scaler_test = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_test = scaler_test.fit_transform(values_test)\n",
    "\n",
    "# create target scaler object\n",
    "target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "target_scaler.fit(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame as supervised learning\n",
    "reframed_train = series_to_supervised(scaled_train, n_hours, 1)\n",
    "reframed_test = series_to_supervised(scaled_test, n_hours, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "to_remove = [['var'+str(i)+'(t-'+str(j)+')' for i in range(1, 4)] for j in range(1, 4)]\n",
    "reframed_train = reframed_train.drop(['var'+str(i)+'(t)' for i in range(4, 12)]+\n",
    "                                     list(itertools.chain.from_iterable(to_remove)), axis=1)\n",
    "reframed_test = reframed_test.drop(['var'+str(i)+'(t)' for i in range(1, 9)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "n_train_hours = 236 * 24 # 80%\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/validation\n",
    "train_X = reframed_train.values[:n_train_hours, :n_obs]\n",
    "train_y = reframed_train.values[:n_train_hours, [24, 25, 26]]\n",
    "val_X = reframed_train.values[n_train_hours:, :n_obs]\n",
    "val_y = reframed_train.values[n_train_hours:, [24, 25, 26]]\n",
    "test_X = reframed_test.values\n",
    "\n",
    "print(train_X.shape, val_X.shape, train_y.shape, val_y.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "model.compile(loss=rmsle,\n",
    "              optimizer = keras.optimizers.Adam(learning_rate=0.0002))\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y,\n",
    "                    epochs=100, batch_size=72,\n",
    "                    validation_data=(val_X, val_y),\n",
    "                    verbose=2, shuffle=False,\n",
    "                    callbacks=[early_stopping, plateau])\n",
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(val_X)\n",
    "val_X = val_X.reshape((val_X.shape[0], n_hours*n_features))\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, val_X[:, -n_features:]), axis=1)\n",
    "inv_yhat = scaler_train.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,range(3)]\n",
    "\n",
    "# invert scaling for actual\n",
    "val_y = val_y.reshape((len(val_y), 3))\n",
    "inv_y = np.concatenate((val_y, val_X[:, -n_features:]), axis=1)\n",
    "inv_y = scaler_train.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,range(3)]\n",
    "\n",
    "# calculate RMSLE\n",
    "rmsle = np.sqrt(mean_squared_log_error(inv_y, inv_yhat))\n",
    "print('Test RMSLE: %.3f' % rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat_test = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for fold, (tr_idx, ts_idx) in enumerate(kfold.split(train)):\n",
    "    print(f\"\\n ====== TRAINING FOLD {fold} =======\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(max_train_size=None, n_splits=10)\n",
    "\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(train)):\n",
    "    print(f\"\\n ====== TRAINING FOLD {fold} =======\\n\")\n",
    "    print(tr_idx, ts_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils.vis_utils import plot_model\n",
    "#model = get_model()\n",
    "#plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
